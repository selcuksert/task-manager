debug: false
logging:
  #file:
  #name: app.log
  level:
    root: info
    '[org.apache.kafka]': error
    '[org.springframework.kafka.config]': info
server:
  port: ${SERVER_PORT:8090}

custom:
  security:
    provider:
      jwt:
        role:
          key: roles
        claim:
          key: realm_access

spring:
  cloud:
    stream:
      function:
        definition: output
      kafka:
        binder:
          auto-create-topics: false
          autoAddPartitions: false
          brokers:
            - ${BROKER_1:localhost:19091}
            - ${BROKER_2:localhost:19092}
            - ${BROKER_3:localhost:19093}
          producer-properties:
            '[key.serializer]': org.apache.kafka.common.serialization.StringSerializer
            '[value.serializer]': io.confluent.kafka.serializers.KafkaAvroSerializer
            '[schema.registry.url]': ${SR_PROT:http}://${SR_HOST:web.poc.local}:${SR_PORT:8081}
      bindings:
        output-out-0:
          destination: tasks
          content-type: application/*+avro
          producer:
            useNativeEncoding: true
  application:
    name: task-writer
  security:
    oauth2:
      resourceserver:
        jwt:
          jwk-set-uri: ${IDP_PROT:http}://${IDP_HOST:idp.poc.local}:${IDP_PORT:80}/auth/realms/corpauth/protocol/openid-connect/certs